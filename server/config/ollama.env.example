# Ollama Configuration Example
# Copy this file to ollama.env and customize as needed

# Ollama host configuration
OLLAMA_HOST=0.0.0.0

# Model configuration
# Default model to use for Minecraft interactions
DEFAULT_MODEL=llama3.2:1b

# API configuration
# Maximum context length for model responses
OLLAMA_MAX_CONTEXT=4096

# Performance tuning
# Number of parallel requests to handle
OLLAMA_NUM_PARALLEL=4

# GPU configuration (if available)
# OLLAMA_GPU_LAYERS=35

# Logging
OLLAMA_DEBUG=false
